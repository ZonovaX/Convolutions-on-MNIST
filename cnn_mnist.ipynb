{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2eb0372a-6544-41b7-8ced-99665ec6e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "604b7449-1239-4565-be64-041b4bc8ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dbc51d05-f765-4855-ba4d-1c9b3991beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "writer = SummaryWriter(\"runs/mnist2\")\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "batch_size = 100;\n",
    "\n",
    "#defining dataset and dataloader\n",
    "#train_ds = TensorDataset(training_data.data.reshape(-1,28*28).float(), training_data.targets)\n",
    "#valid_ds = TensorDataset(test_data.data.reshape(-1,28*28).float(), test_data.targets)\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1,1,28,28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return F.log_softmax(xb.view(-1, xb.size(1)), dim=1)\n",
    "\n",
    "#defining loss function, weights, and bias tensors\n",
    "loss_func = F.nll_loss\n",
    "lr = 0.05\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "def accuracy(xb, yb):\n",
    "    max_xb = torch.argmax(xb,dim=1)\n",
    "    return (max_xb == yb).float().mean()\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt = None):\n",
    "    loss = loss_func(model(xb),yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def acc_batch(model, xb, yb):\n",
    "    acc = accuracy(model(xb),yb)\n",
    "    return acc, len(xb)\n",
    "        \n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    n_total_steps = len(train_dl)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        i=0\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            i+=1\n",
    "            running_loss += loss_batch(model,loss_func,xb, yb, opt)[0]\n",
    "            if i%100==0:\n",
    "                writer.add_scalar('training loss',running_loss/100, epoch*n_total_steps + i)\n",
    "                running_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb,yb in valid_dl])\n",
    "            accs, nums = zip(*[acc_batch(model, xb, yb) for xb,yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses,nums))/np.sum(nums)\n",
    "        val_acc = np.sum(np.multiply(accs,nums))/np.sum(nums)\n",
    "        print(epoch, val_loss,val_acc)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e35af2d-fb96-493e-978c-3039dd44fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_data(training_data,test_data,batch_size)\n",
    "examples = iter(train_dl)\n",
    "example_data, example_targets = next(examples)\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images_5',img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "17fec38b-daf5-4a74-834e-84a89fe1cba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "875f6550-2c63-4e7e-848e-1d140faeacb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7431335246562958 0.7125999963283539\n",
      "1 0.5921678930521012 0.7962999987602234\n",
      "2 0.557761258482933 0.8027000010013581\n",
      "3 0.49311653077602385 0.820200001001358\n",
      "4 0.4716861736774445 0.828600001335144\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 5;\n",
    "train_dl, valid_dl = get_data(training_data,test_data,batch_size)\n",
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr = lr, momentum = 0.9)\n",
    "writer.add_graph(model, example_data)\n",
    "writer.close()\n",
    "fit(total_epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5d67a3a8-19cb-4fda-b418-17d7688db797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.5868e-03, 9.5361e-01, 4.3575e-05, 3.9910e-02, 2.9719e-04, 1.1410e-05,\n",
       "         3.9765e-04, 6.9662e-05, 6.9238e-05, 3.8486e-06],\n",
       "        [6.3568e-05, 9.5347e-06, 1.4743e-05, 7.2948e-05, 5.0899e-06, 7.5699e-02,\n",
       "         4.8607e-05, 9.2089e-01, 1.7275e-03, 1.4704e-03],\n",
       "        [2.2801e-04, 7.3300e-06, 9.4397e-05, 2.2896e-03, 1.2300e-04, 4.8264e-04,\n",
       "         6.0899e-05, 9.4662e-04, 3.8296e-04, 9.9538e-01]],\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(example_data)[0:3].exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "56dfb572-2410-424e-9c56-c344bcc30d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 9])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_targets[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7db7c691-3b7f-4b4a-a914-d37434f13a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-74.0803, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(example_data)[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "23df7d5a-13d3-445a-a18c-9293f9dc1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.view(-1,1,28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32b44f-277c-4f0e-b729-555d187e1842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
